# ğŸ§  Decifrando a Caixa Preta: Tornando Modelos de IA ExplicÃ¡veis com LIME

Este repositÃ³rio apresenta um projeto acadÃªmico que explora os fundamentos da **InteligÃªncia Artificial ExplicÃ¡vel (XAI)**, com foco na aplicaÃ§Ã£o prÃ¡tica da biblioteca **LIME** para tornar mais compreensÃ­veis os resultados de um modelo preditivo de crÃ©dito bancÃ¡rio.

## ğŸ‘¤ Autor

**Jeferson Chiquesi**  
Estudante de GestÃ£o da Tecnologia da InformaÃ§Ã£o â€“ UniFECAF  
GitHub: [@jefersonchiquesi](https://github.com/jefersonchiquesi)

---

## ğŸ¯ Objetivo

Tornar um modelo de classificaÃ§Ã£o de crÃ©dito mais transparente, revelando **quais caracterÃ­sticas influenciam as decisÃµes** do algoritmo. A tÃ©cnica utilizada Ã© o **LIME (Local Interpretable Model-agnostic Explanations)**, capaz de gerar explicaÃ§Ãµes locais mesmo em modelos considerados "caixas-pretas".

---

## ğŸ—‚ï¸ ConteÃºdo do Projeto

- `notebook/lime_credit_analysis.ipynb`: Jupyter Notebook com todo o pipeline, do prÃ©-processamento Ã  explicaÃ§Ã£o via LIME.
- `outputs/`: ContÃ©m imagens com explicaÃ§Ãµes geradas pelo LIME.
- `requirements.txt`: DependÃªncias do projeto.
- `README.md`: Este documento.

---

## ğŸ§ª Tecnologias e Bibliotecas

- Python 3.11+
- Pandas, NumPy, Scikit-learn
- Matplotlib, Seaborn
- LIME
- Jupyter Notebook

---

## ğŸ“Š Dataset Utilizado

- **German Credit Data** â€“ DisponÃ­vel na UCI Machine Learning Repository.
- Atributos: status de crÃ©dito, idade, histÃ³rico bancÃ¡rio, valor do emprÃ©stimo, entre outros.
- Classes: `Bom` ou `Ruim`.

---

## ğŸ§  Modelo Preditivo

- **Algoritmo:** Random Forest
- **Tarefa:** ClassificaÃ§Ã£o binÃ¡ria (crÃ©dito bom ou ruim)
- **MÃ©trica Avaliada:** AcurÃ¡cia

---

## ğŸ” ExplicaÃ§Ãµes com LIME

A biblioteca LIME foi utilizada para explicar **instÃ¢ncias individuais** do conjunto de teste. Cada explicaÃ§Ã£o mostra:

- As **principais variÃ¡veis** que influenciaram a prediÃ§Ã£o;
- O **peso e direÃ§Ã£o** de cada variÃ¡vel na decisÃ£o;
- RepresentaÃ§Ã£o grÃ¡fica de forma intuitiva.

---

## ğŸ’¡ Resultados e Insights

- O LIME permitiu visualizar o impacto de variÃ¡veis como `duration`, `credit_amount`, `age`, e `checking_status` na decisÃ£o do modelo.
- Evidenciou que mesmo modelos complexos podem ser explicados de forma **transparente e acessÃ­vel**.
- ExplicaÃ§Ãµes ajudam a criar **confianÃ§a no modelo**, essencial em setores sensÃ­veis como o financeiro.

---

## âš ï¸ LimitaÃ§Ãµes

- O LIME gera explicaÃ§Ãµes **locais**, ou seja, vÃ¡lidas apenas para instÃ¢ncias especÃ­ficas.
- Pode ser sensÃ­vel a ruÃ­do ou atributos altamente correlacionados.
- NÃ£o substitui uma anÃ¡lise global do modelo.

---

## ğŸ” Ã‰tica, SeguranÃ§a e GovernanÃ§a

- O projeto ressalta a importÃ¢ncia da **explicabilidade em modelos de decisÃ£o automatizada**, especialmente em contextos com alto impacto social.
- Contribui para um uso mais responsÃ¡vel da IA.

---

## ğŸ§­ Como Rodar o Projeto

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/jefersonchiquesi/xai-lime-projeto.git
   cd xai-lime-projeto
python -m venv .venv
source .venv/bin/activate  # ou .venv\Scripts\activate no Windows
Instale as dependÃªncias:

bash
Copiar
Editar
pip install -r requirements.txtExecute o Jupyter Notebook:

bash
Copiar
Editar
jupyter notebook


ğŸ¤ ContribuiÃ§Ãµes
Este projeto foi desenvolvido como parte da disciplina de Explainable AI e estÃ¡ aberto para sugestÃµes e melhorias.

